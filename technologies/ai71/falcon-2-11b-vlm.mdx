---
title: "Falcon 2 11B VLM"
author: "ai71"
description: "Falcon 2 11B VLM is an advanced variant of the Falcon 2 series, developed by the Technology Innovation Institute (TII). This model is designed to excel in multimodal tasks, bridging the gap between visual and linguistic data processing."
---

# About Falcon 2 11B VLM
Falcon2-11B-VLM is an 11B parameters causal decoder-only model built by TII and trained on over 5,000B tokens of RefinedWeb enhanced with curated corpora. To bring vision capabilities, we integrate the pretrained CLIP ViT-L/14 vision encoder with our Falcon2-11B chat-finetuned model and train with image-text data. For enhancing the VLM's perception of fine-grained details w.r.t small objects in images, we employ a dynamic encoding mechanism at high-resolution for image inputs.
The model is built on the same robust foundation as Falcon 2 11B, featuring 11 billion parameters. It matches or exceeds the performance of other leading models, such as Meta’s Llama 3 8B and Google’s Gemma 7B, particularly in tasks that require vision-language integration.

| General  |  |
| --- | --- |
| Relese date |  May 13, 2024 |
| Author | [AI71](https://ai71.ai/)  |
| Dataset | https://huggingface.co/tiiuae/falcon-11B |
| Type | Vision Language Model |


## Falcon 2 Tutorials
<TechTutorials/>
